import { GoogleGenerativeAI } from "@google/generative-ai";

export const chat = async (req, res) => {
    
        // 1. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        const { message } = req.body;
        const files = req.files || [];

        // 2. Ø¥Ø¹Ø¯Ø§Ø¯ Gemini
        const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
        
        // ðŸ›‘ ØªØµØ­ÙŠØ­ 1: Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ØºÙ„Ø·ØŒ Ø§Ù„ØµØ­ Ù‡Ùˆ gemini-1.5-flash
        const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

        const parts = []; // Ù‡Ù†Ø³Ù…ÙŠÙ‡Ø§ parts Ø¹Ø´Ø§Ù† Ø¯Ù‡ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ

        // ðŸ›‘ ØªØµØ­ÙŠØ­ 2: Ø§Ù„Ù„ÙˆØ¨ Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ø¹Ù„Ù‰ files Ù…Ø´ data
        if (files.length > 0) {
            files.forEach((file) => {
                if (file.buffer) {
                    parts.push({
                        inlineData: {
                            data: file.buffer.toString("base64"),
                            mimeType: file.mimetype,
                        },
                    });
                }
            });
        }

        // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†ØµÙŠØ©
        if (message) {
            parts.push({ text: message });
        } else if (files.length > 0) {
            parts.push({ text: "Ø´Ø±Ø­ Ù„Ù„ØµÙˆØ±Ø©" });
        }

        // ðŸ›‘ ØªØµØ­ÙŠØ­ 3: Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØµØ­ Ù‡ÙŠ generateContent Ù…Ø´ predict
        const result = await model.generateContent(parts);
        const response = await result.response;
        
        // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ø¯
        const textResponse = response.text();

        return res.status(200).json({
            success: true, 
            message: "success chat", 
            result: textResponse 
        });
      }